{
  "provider": "huggingface",
  "model_name": "meta-llama/Llama-3.1-8B-Instruct",
  "huggingface": {
    "api_url": "https://api-inference.huggingface.co/models/",
    "max_tokens": 1000,
    "temperature": 0.7
  },
  "ollama": {
    "host": "http://localhost:11434"
  }
} 